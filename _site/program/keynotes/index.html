<!doctype html>
<!--
  Minimal Mistakes Jekyll Theme 4.16.4 by Michael Rose
  Copyright 2013-2019 Michael Rose - mademistakes.com | @mmistakes
  Free for personal and commercial use under the MIT license
  https://github.com/mmistakes/minimal-mistakes/blob/master/LICENSE
-->
<html lang="en" class="no-js">
  <head>
    <meta charset="utf-8">

<!-- begin _includes/seo.html --><title>Keynote - ALTA 2023</title>
<meta name="description" content="EMNLP 2022 Keynote Speakers.">



<meta property="og:type" content="website">
<meta property="og:locale" content="en_US">
<meta property="og:site_name" content="ALTA 2023">
<meta property="og:title" content="Keynote">
<meta property="og:url" content="http://localhost:4000/program/keynotes/">


  <meta property="og:description" content="EMNLP 2022 Keynote Speakers.">





  <meta name="twitter:site" content="@altanlp">
  <meta name="twitter:title" content="Keynote">
  <meta name="twitter:description" content="EMNLP 2022 Keynote Speakers.">
  <meta name="twitter:url" content="http://localhost:4000/program/keynotes/">

  
    <meta name="twitter:card" content="summary">
    
  

  







  

  


<link rel="canonical" href="http://localhost:4000/program/keynotes/">







  <script type="application/ld+json">
    {
      "@context": "https://schema.org",
      "@type": "Person",
      "name": "alta",
      "url": "http://localhost:4000",
      "sameAs": null
    }
  </script>







<!-- end _includes/seo.html -->


<link href="_pages/home.md" type="application/atom+xml" rel="alternate" title="ALTA 2023 Feed">

<!-- https://t.co/dKP3o1e -->
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<script>
  document.documentElement.className = document.documentElement.className.replace(/\bno-js\b/g, '') + ' js ';
</script>

<!-- For all browsers -->
<link rel="stylesheet" href="/assets/css/main.css">

<!--[if IE ]>
  <style>
    /* old IE unsupported flexbox fixes */
    .greedy-nav .site-title {
      padding-right: 3em;
    }
    .greedy-nav button {
      position: absolute;
      top: 0;
      right: 0;
      height: 100%;
    }
  </style>
<![endif]-->



    <!-- start custom head snippets -->

<!-- insert favicons. use https://realfavicongenerator.net/ -->
<link rel="apple-touch-icon" sizes="57x57" href="/assets/images/apple-touch-icon-57x57.png">
<link rel="apple-touch-icon" sizes="60x60" href="/assets/images/apple-touch-icon-60x60.png">
<link rel="apple-touch-icon" sizes="72x72" href="/assets/images/apple-touch-icon-72x72.png">
<link rel="apple-touch-icon" sizes="76x76" href="/assets/images/apple-touch-icon-76x76.png">
<link rel="apple-touch-icon" sizes="114x114" href="/assets/images/apple-touch-icon-114x114.png">
<link rel="apple-touch-icon" sizes="120x120" href="/assets/images/apple-touch-icon-120x120.png">
<link rel="apple-touch-icon" sizes="144x144" href="/assets/images/apple-touch-icon-144x144.png">
<link rel="apple-touch-icon" sizes="152x152" href="/assets/images/apple-touch-icon-152x152.png">
<link rel="icon" type="image/png" href="/assets/images/favicon-32x32.png" sizes="32x32">
<link rel="icon" type="image/png" href="/assets/images/favicon-16x16.png" sizes="16x16">
<link rel="mask-icon" href="/assets/images/safari-pinned-tab.svg" color="#5bbad5">
<meta name="msapplication-TileColor" content="#2b5797">
<meta name="msapplication-TileImage" content="/assets/images/mstile-144x144.png">
<meta name="theme-color" content="#ffffff">

<!-- end custom head snippets -->

  </head>

  <body class="layout--single">

    <!--[if lt IE 9]>
<div class="notice--danger align-center" style="margin: 0;">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience.</div>
<![endif]-->

    
<style type="text/css">
.tmp-disable{
color:#CCCCCC
}
</style>

<div class="masthead">
  <div class="masthead__inner-wrap">
    <div class="masthead__menu">
      <nav id="site-nav" class="greedy-nav">
        
          <a class="site-logo" href="/"><img src="/assets/images/logos/alta_2023_logo.png" alt=""></a>
        
        <a class="site-title" href="/"> </a>
        <ul class="visible-links"><li class="masthead__menu-item">
                <a href="/calls/main_conference_papers/" ><span style="color:#999999;">CFP</span></a>
              </li><li class="masthead__menu-item">
                <a href="/program/" >Programme</a>
              </li><li class="masthead__menu-item">
                <a href="/venue" >Venue</a>
              </li><li class="masthead__menu-item">
                <a href="/organization" >Committees</a>
              </li><li class="masthead__menu-item">
                <a href="/mentoring" ><span style="color:#999999;">Mentoring</span></a>
              </li><li class="masthead__menu-item">
                <a href="/sponsors/" >Sponsors</a>
              </li><li class="masthead__menu-item">
                <a href="/contact" >Contact</a>
              </li></ul>
        
        <button class="greedy-nav__toggle hidden" type="button">
          <span class="visually-hidden">Toggle menu</span>
          <div class="navicon"></div>
        </button>
        <ul class="hidden-links hidden"></ul>
      </nav>
    </div>
  </div>
</div>


    <div class="initial-content">
      



<div id="main" role="main">
  
  <div class="sidebar sticky">
  
  
    
      
      
      
      
    
    
      

<nav class="nav__list">
  
  <ul class="nav__items">
    
      <li>
        
          <span class="nav__sub-title">Program Details</span>
        

        
        <ul>
          
            
            

            
            

            <li><a href="/program/" class="">Conference Program</a></li>
          
            
            

            
            

            <li><a href="/program/keynotes/" class="active">Keynote</a></li>
          
            
            

            
            

            <li><a href="/program/workshops/" class="">Workshops</a></li>
          
            
            

            
            

            <li><a href="/program/tutorials/" class="">Tutorials</a></li>
          
            
            

            
            

            <li><a href="/program/careers_in_nlp/" class="">Careers in NLP</a></li>
          
        </ul>
        
      </li>
    
  </ul>
</nav>
    
  
  </div>


  <article class="page" itemscope itemtype="https://schema.org/CreativeWork">
    <meta itemprop="headline" content="Keynote">
    <meta itemprop="description" content="EMNLP 2022 Keynote Speakers.">
    
    

    <div class="page__inner-wrap">
      
        <header>
          <h1 id="page-title" class="page__title" itemprop="headline">Keynote
</h1>
          
        </header>
      

      <section class="page__content" itemprop="text">
        
          <aside class="sidebar__right sticky">
            <nav class="toc">
              <header><h4 class="nav__title"><i class="fas fa-cog"></i> On this page</h4></header>
              <ul class="toc__menu">
  <li><a href="#speaker-mona-diab">Speaker: Mona Diab</a>
    <ul>
      <li><a href="#towards-a-responsible-nlp-walking-the-walk">Towards a Responsible NLP: Walking the walk</a></li>
    </ul>
  </li>
  <li><a href="#speaker-neil-cohn">Speaker: Neil Cohn</a>
    <ul>
      <li><a href="#the-multimodal-language-faculty-and-the-visual-languages-of-comics">The multimodal language faculty and the visual languages of comics</a></li>
    </ul>
  </li>
  <li><a href="#speaker-gary-marcus">Speaker: Gary Marcus</a>
    <ul>
      <li><a href="#talk-video">Talk Video</a></li>
      <li><a href="#towards-a-foundation-for-agi">Towards a Foundation for AGI﻿</a></li>
    </ul>
  </li>
  <li><a href="#speaker-nazneen-rajani">Speaker: Nazneen Rajani</a>
    <ul>
      <li><a href="#takeaways-from-a-systematic-study-of-75k-models-on-hugging-face">Takeaways from a systematic study of 75K models on Hugging Face</a></li>
    </ul>
  </li>
</ul>
            </nav>
          </aside>
        
        <p>The following speakers have graciously agreed to give keynotes at EMNLP 2022.</p>

<style>
p.speaker-bio { font-style: italic; font-size: 80%; }
</style>

<!-- ### Humans Learn From Task Descriptions and So Should Our Models
*Main Conference Keynote<br>Monday, June 7, 08:00--09:00 PDT*

Joint work with Timo Schick and Sahana Udupa

Task descriptions are ubiquitous in human learning.  They are usually accompanied by a few examples, but there is little human learning that is based on examples only. In contrast, the typical learning setup for NLP tasks lacks task descriptions and is supervised with 100s or 1000s of examples.

We introduce Pattern-Exploiting Training (PET), an approach to learning that mimicks human learning in that it leverages task descriptions in few-shot settings.  PET is built on top
of a pretrained language model that "understands" the task description, especially after finetuning, resulting in excellent performance compared to other few-shot methods. In particular, a model trained with PET outperforms GPT-3 even though it has 99.9% fewer parameters.

In the last part of the talk, I will show how bias in NLP models can be addressed using task descriptions. Instructing a model to reveal and reduce its biases is remarkably effective and may contribute in the future to a fairer and more inclusive NLP. -->

<h2 id="speaker-mona-diab">Speaker: Mona Diab</h2>

<p><img src="/assets/images/keynotes/keynote_Speaker_Mona_Diab.jpg" alt="Mona Diab" class="align-center" /></p>

<h3 id="towards-a-responsible-nlp-walking-the-walk">Towards a Responsible NLP: Walking the walk</h3>

<p>In a world of racing to get the best systems on leaderboards, winning best shared tasks, building the largest LM, are we losing our soul as a scientific enterprise? Do we need to re-orient and re-pivot NLP? If so, what is needed to make this happen? Can we chart together a program where we ensure that science is the pivotal ingredient in CL/NLP? Could Responsible NLP be an avenue  that could lead us back towards that goal? In this talk, in the spirit of EMpirical NLP, I will explore some “practical” ideas around framing a Responsible NLP vision hoping to achieve a higher scientific standard for our field, addressing issues from the “how” we conduct our research and venturing into the “what” we work on and produce using tenets from responsible mindset perspective. I will pose more questions than answers. This is a call to action, an invitation to start a real global community conversation, hopefully engaging all stakeholders: academia, industry, government and civic society.</p>

<p class="speaker-bio">Mona Diab is the Lead Responsible AI Research Scientist with Meta.  She is also a full Professor of Computer Science at the George Washington University (on leave) where she directs the CARE4Lang NLP Lab. Before joining Meta, she led the  Lex Conversational AI project within Amazon AWS AI. Her current focus is on Responsible AI and how to operationalize it for NLP technologies. Her interests span building robust technologies for low resource scenarios with a special interest in Arabic technologies, (mis) information propagation, computational socio-pragmatics, computational psycholinguistics, NLG evaluation metrics, Language modeling and resource creation. Mona has served the community in several capacities: Elected President of SIGLEX and SIGSemitic, and she currently serves as the elected VP for ACL SIGDAT, the board supporting EMNLP conferences. She has delivered tutorials and organized numerous workshops and panels around Arabic processing, Responsible NLP, Code Switching, etc. She is a cofounder of CADIM (Consortium on Arabic Dialect Modeling, previously known as Columbia University Arabic Dialects Modeling Group), in 2005, which served as a world renowned reference point on Arabic Language Technologies. Moreover she helped establish two research trends in NLP, namely computational approaches to Code Switching and Semantic Textual Similarity. She is also a founding member of the *SEM conference, one of the top tier conferences in NLP. Mona has published more than 250 peer reviewed articles.</p>

<p class="speaker-bio">Affiliation: Meta Responsible AI</p>

<h2 id="speaker-neil-cohn">Speaker: Neil Cohn</h2>

<p><img src="/assets/images/keynotes/keynote_Speaker_Neil_Cohn.jpg" alt="Neil Cohn" class="align-center" /></p>

<h3 id="the-multimodal-language-faculty-and-the-visual-languages-of-comics">The multimodal language faculty and the visual languages of comics</h3>

<p>Contrary to the notions of language as an amodal system, natural human communication is multimodal and combines speech, gestures, writing, and pictures. To account for this, recent work has proposed that our vocal, bodily, and graphic modalities persist in parallel in a multimodal language faculty, and both unimodal and multimodal expressions arise out of emergent states of a shared architecture. Such a model carries different expectations for the ways in which modalities may be similar or different from each other, and how they may interact. I will highlight these properties specifically for our graphic modality, which I argue can manifest in full visual languages when displaying both a systematic lexicon and complex grammar. I will use analysis of a corpus of several hundred annotated comics to show distinctive patterns that suggest they are drawn in different visual languages. Yet, I will also show that consistent “universal” linguistic principles persist across this structural diversity. Finally, I will argue that a multimodal language faculty requires us to change our conception of linguistic relativity, and I will show how subtle structures of spoken languages permeate across to visual languages. Altogether, this work argues for a multimodal basis of linguistic structure, and heralds a reconsideration of what constitutes the language system.</p>

<p class="speaker-bio">Neil Cohn is an American cognitive scientist best known for his research on the overlap in structure and cognition between language and graphic communication like comics and emoji. He is the author of 80+ academic papers, 4 academic books, and 2 graphic novels. He received his PhD in cognitive psychology at Tufts University and is currently an associate professor at the Department of Cognition and Communication at Tilburg University in The Netherlands. His work can be found online at <www.visuallanguagelab.com>.</www.visuallanguagelab.com></p>

<p class="speaker-bio">Affiliation: Tilburg University, Department of Communication and Cognition</p>

<h2 id="speaker-gary-marcus">Speaker: Gary Marcus</h2>

<p><img src="/assets/images/keynotes/keynote_Speaker_Gary_Marcus.png" alt="Gary Marcus" class="align-center" /></p>

<h3 id="talk-video"><a href="https://www.dropbox.com/s/816jhaqp9nqcnry/EMNLP%20odf%20video.mp4?dl=0">Talk Video</a></h3>

<h3 id="towards-a-foundation-for-agi">Towards a Foundation for AGI﻿</h3>

<p>Large pretrained language models like GPT-3 and PaLM  have generated enormous enthusiasm, and are capable of producing remarkably fluent language. But they have also been criticized on many grounds, and described as “stochastic parrots.” Are they adequate as a basis for artificial general intelligence [AGI], and if not, what would a better foundation for general intelligence look like?</p>

<p class="speaker-bio">Gary Marcus is a leading voice in artificial intelligence. He is a scientist, best-selling author, and serial entrepreneur (Founder of Robust.AI and Geometric.AI, acquired by Uber). He is well-known for his challenges to contemporary AI, anticipating many of the current problems decades in advance, and for his research in human language development and cognitive neuroscience. An Emeritus Professor of Psychology and Neural Science at NYU, he is the author of five books, including, The Algebraic Mind, Kluge, The Birth of the Mind, and the New York Times Bestseller Guitar Zero. He has often contributed to The New Yorker, Wired, and The New York Times. His most recent book, Rebooting AI, with Ernest Davis, is one of Forbes’s 7 Must Read Books in AI. </p>

<p class="speaker-bio">Affiliation: NYU (Emeritus) NYU (Emeritus) </p>

<h2 id="speaker-nazneen-rajani">Speaker: Nazneen Rajani</h2>

<p><img src="/assets/images/keynotes/Nazneen_Rajani.jpg" alt="Nazneen Rajani" class="align-center" /></p>

<h3 id="takeaways-from-a-systematic-study-of-75k-models-on-hugging-face">Takeaways from a systematic study of 75K models on Hugging Face</h3>

<p>Abstract: Language models trained using transformers dominate the NLP model landscape, making Hugging Face (HF) the defacto hub for sharing, benchmarking, and evaluating NLP models.  The HF hub provides a rich resource for understanding how language models evolved, opening up research questions such as ‘Is there a correlation between model documentation and its usage?’, ’How have the models evolved?’, ‘What do users document about their models?’. In the first part of my talk, I’ll give a macro-level view of how the NLP model landscape has evolved based on our systematic study of 75K HF models.
 
In the second part, I’ll discuss advances, challenges and opportunities in evaluating and documenting NLP models developed in an industry setting. Based on the results, do we see a paradigm shift from model-centric to data-centric evaluation and documentation?</p>

<p class="speaker-bio">Nazneen is a Research Lead at HuggingFace, a startup with a mission to democratize ML, leading data-centric ML research which involves systematically analyzing, curating, and automatically annotating data. Before HF, she worked at Salesforce Research with Richard Socher and led a team of researchers focused on building robust natural language generation systems based on LLMs. She completed her Ph.D. in CS at UT-Austin with Prof. Ray Mooney.</p>

<p class="speaker-bio">Nazneen has over 30 papers accepted at ACL, EMNLP, NAACL, NeurIPs, and ICLR and has her research covered by Quanta magazine, VentureBeat, SiliconAngle, ZDNet, and Datanami. She is also teaching a course on interpreting ML models with Corise – http://corise.com/go/nazneen. More details about her work can be found here https://www.nazneenrajani.com/</p>

<!--## Dhruv Batra

![Dhruv Batra](/assets/images/keynotes/Dhruv_Batra.jpg){: .align-center}

### From Disembodied to Embodied Multimodal Learning
*Main Conference Keynote<br>Monday, June 7, 16:00--17:00 PDT*

Embodied AI is the science and engineering of intelligent machines with a physical or virtual embodiment (e.g., robots and egocentric personal assistants). Imagine walking up to a home assistant robot and asking “Hey robot – can you go check if my laptop is on my desk? And if so, bring it to me”. Or asking an egocentric AI assistant (operating on your smart glasses): “Hey – where did I last see my keys?”. The embodiment hypothesis is the idea that “intelligence emerges in the interaction of an agent with an environment and as a result of sensorimotor activity”. In this talk, I will argue that we should take the embodiment hypothesis (and it implications) seriously. And I will weave through a line of work happening at my group at Georgia Tech and with collaborators at FAIR illustrating the shift from disembodied vision-and-language (multimodal) agents towards such embodied agents.

Dhruv Batra is an Associate Professor in the School of Interactive Computing at Georgia Tech and a Research Scientist at Facebook AI Research (FAIR). His research interests lie at the intersection of machine learning, computer vision, natural language processing, and AI. The long-term goal of his research is to develop agents that 'see' (or more generally perceive their environment through vision, audition, or other senses), 'talk' (i.e. hold a natural language dialog grounded in their environment), 'act' (e.g. navigate their environment and interact with it to accomplish goals), and 'reason' (i.e., consider the long-term consequences of their actions). He is a recipient of the Presidential Early Career Award for Scientists and Engineers (PECASE) 2019. ([Full Biography](https://www.cc.gatech.edu/~dbatra/files/bio.txt))
{: .speaker-bio}


## Shakir Mohamed

![Shakir Mohamed](/assets/images/keynotes/Shakir_Mohamed.jpg){: .align-center}

### Generating Reality: Technical and Social Explorations in Generative Machine Learning Research
*Main Conference Keynote<br>Tuesday, June 8, 08:00--09:00 PDT*

We are going to play with the meaning and implications of the word ‘generative’ in this talk. A generative approach to machine learning is now widely-established, and we now have techniques to generate, simulate, confabulate and fake all sorts of data we can find, natural language included. Using my own research, I’d like to review the statistical foundations of this generative approach and some of the questions that still seem open to us. Yet, no act of generation exists outside of the social world. So, I’d like to also explore how these technical questions are instead social questions. I’d again like to use my own experience to explore the sociotechnical theories that can direct us towards a more critical practice of machine learning. This leads to a generative field of machine learning that transforms criticism into productive alternatives: a field that continues to seek creative solutions for challenging problems, but is more deeply embedded, concerned and responsible for the new technological realities it seeks to generate.

Dr Shakir Mohamed works on technical and sociotechnical questions in machine learning research, aspiring to make contributions to machine learning principles, applied problems in healthcare and environment, and ethics and diversity. Shakir is a research scientist and lead at DeepMind in London, an Associate Fellow at the Leverhulme Centre for the Future of Intelligence, and a Honorary Professor of University College London. Shakir is also a founder and trustee of the Deep Learning Indaba, a grassroots organisation aiming to build pan-African capacity and leadership in AI. Shakir was the General Chair for the 2021 International conference on Learning Representations, and a member of the Royal Society's Diversity Committee.
{: .speaker-bio}


## Thamar Solorio

![Thamar Solorio](/assets/images/keynotes/Thamar_Solorio.jpg){: .align-center}

### Moving the needle in NLP technology for the processing of code-switched language
*Main Conference Keynote<br>Tuesday, June 8, 16:00--17:00 PDT*

Multilingual speakers are known to mix their languages when communicating with other multilingual speakers in what is called code-switching. While worldwide monolingual speakers are outnumbered by multilingual ones, most of the NLP technologies being developed nowadays target monolingual speakers of a handful of languages. This is also true of multilingual models that, although designed to process many languages, still assume a one language per input setting. These multilingual models have been shown to decrease performance when the input has code-switching in several tasks, including language identification, part of speech tagging, named entity recognition and machine translation.  In this talk, I will give an overview of recent work that aims to address the linguistic challenges that code-switching poses to state of the art models, where the goal is to leverage pretrained models from high resource languages. This code-switching research is part of my long term goal of increasing the coverage of human language abilities by NLP technologies, disrupting the status quo of non-equitable systems.

Thamar Solorio is an Associate Professor of the Department of Computer Science at the University of Houston (UH). She holds graduate degrees in Computer Science from the Instituto Nacional de Astrofísica, Óptica y Electrónica, in Puebla, Mexico. Her research interests include information extraction from social media data, enabling technology for code-switched data, stylistic modeling of text and more recently multimodal approaches to online content understanding. She is the director and founder of the Research in Text Understanding and Language Analysis Lab at UH. She is the recipient of an NSF CAREER award for her work on authorship attribution, and recipient of the 2014 Emerging Leader ABIE Award in Honor of Denice Denton. She is an elected board member of the North American Chapter of the Association of Computational Linguistics (2020-2021). Her research is currently funded by the National Science Foundation and ADOBE, and in the past she has received support from the Office of Naval Research and the Defense Advanced Research Projects Agency (DARPA).
{: .speaker-bio}


## Aya Soffer

![Aya Soffer](/assets/images/keynotes/Aya_Soffer.jpg){: .align-center}

### Project Debater - from grand challenge to business applications, behind the scenes and lessons learned
*Industry Track Keynote<br>Wednesday, June 9, 08:00--09:00 PDT*

Project Debater started as an IBM grand challenge idea in 2011, and eventually competed on stage with a world-renowned debater in 2019. The team has since been further developing the underlying technology, applying it to various business use cases, and is providing access to the underlying tech for non-commercial use. In this talk I will provide a behind the scenes perspective on developing such a project from an idea to a machine that can debate humans, highlight some of the technical innovations including the recent publication in Nature, and discuss various business applications of the technology and how it fits in the overall Language Strategy for IBM Research.

Dr. Aya Soffer is Vice President of AI Technologies for the IBM Research AI organization and the Director of the IBM Research - Haifa lab. Her Research focus is natural language understanding and conversational systems and their application in customer care and other enterprise applications. In this role Dr. Soffer is responsible for setting the strategy and working with IBM scientists around the world to shape their ideas into new AI technology, and with IBM’s product groups and customers to drive Research innovation into the market.  In her 20 years at IBM, Dr. Soffer has led several strategic initiatives that grew into successful IBM products and solutions in the Big Data and AI space including the original Watson system and more recently Project Debater. She has authored over 50 peer-reviewed papers and served as an invited speaker in numerous conferences.
{: .speaker-bio}


## Dan Weld

![Dan Weld](/assets/images/keynotes/Dan_Weld.jpg){: .align-center}

### Semantic Scholar - Advanced NLP to Accelerate Scientific Research
*Industry Track Keynote<br>Wednesday, June 9, 16:00--17:00 PDT*

Semantic Scholar (S2) is a 40 person effort at the Allen Institute for Artificial Intelligence that drives a website used by almost 100M people each year. Our mission is to accelerate the progress of scientific research with augmented intelligence - advanced tools that make it easier to find relevant research, digest it quickly, and make connections between different problems and approaches. This talk will survey some of the NLP advances underlying S2, from the identification of emerging scientific concepts to extreme abstractive summarization, full-document understanding, and fact checking.

Daniel S. Weld is Thomas J. Cable / WRF Professor in the Paul G. Allen School of Computer Science & Engineering, manages the Semantic Scholar research group at the Allen Institute of Artificial Intelligence, and is Venture Partner at the Madrona Venture Group.  After formative education at Phillips Academy, he received bachelor's degrees in both Computer Science and Biochemistry at Yale University in 1982. He landed a Ph.D. from the MIT Artificial Intelligence Lab in 1988, received a Presidential Young Investigator's award in 1989, an Office of Naval Research Young Investigator's award in 1990, was named AAAI Fellow in 1999 and deemed ACM Fellow in 2005. Dan was a founding editor for the Journal of AI Research, was area editor for the Journal of the ACM.  Dan has co-founded three companies, Netbot (sold to Excite), Adrelevance (sold to Media Metrix), and Nimble technology (sold to Actuate).
{: .speaker-bio}-->


        
      </section>

      <footer class="page__meta">
        
        


        
      </footer>

      

      
    </div>

    
  </article>

  
  
</div>

    </div>

    

    <div class="page__footer">
      <footer>
        <!-- start custom footer snippets -->

<!-- end custom footer snippets -->
        <div class="page__footer-follow">
  <ul class="social-icons">
    
      <li><strong>Follow:</strong></li>
    

    
      
        
          <li><a href="https://twitter.com/altanlp" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-twitter-square" aria-hidden="true"></i> Twitter</a></li>
        
      
        
          <li><a href="https://github.com/ruixing76/alta2023" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-github" aria-hidden="true"></i> GitHub</a></li>
        
      
        
      
        
      
        
      
    

    <li><a href="_pages/home.md"><i class="fas fa-fw fa-rss-square" aria-hidden="true"></i> Feed</a></li>
  </ul>
</div>

<div class="page__footer-copyright">&copy; 2023 alta. Powered by <a href="https://jekyllrb.com" rel="nofollow">Jekyll</a> &amp; <a href="https://mademistakes.com/work/minimal-mistakes-jekyll-theme/" rel="nofollow">Minimal Mistakes</a>.</div>

      </footer>
    </div>

    
  <script src="/assets/js/main.min.js"></script>
  <script defer src="https://use.fontawesome.com/releases/v5.8.2/js/all.js" integrity="sha384-DJ25uNYET2XCl5ZF++U8eNxPWqcKohUUBUpKGlNLMchM7q4Wjg2CUpjHLaL8yYPH" crossorigin="anonymous"></script>













  </body>
</html>
